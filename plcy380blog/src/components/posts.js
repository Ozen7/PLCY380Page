import ConfirmationImage from "./img/image.png";
import email from "./img/email.png";
import reqs from "./img/Screenshot 2024-12-06 at 11.55.37 PM.png"
import prog1 from "./img/IMG_1547.png"
import prog2 from "./img/IMG_1570.png"
import prog3 from "./img/IMG_1592.png"
export const posts = [
  {
    title: "PLCY Changemaker Challenge 6",
    body: (
      <>
        <h2>Challenge Chosen, Supporting Materials</h2>
        <p>
        I chose Challenge H: The puchase challenge for this changemaker.
        </p>
        <p>
        Since my topic is about Generative AI and its effects on the social space, I decided to contribute to the online artist community by commissioning myself a new profile picture!
        I asked my artist friends and family about the proper ettiquette, and found an artist through one of my sisters that was familiar with the
        source material of the profile picture that I wanted, which was from a show called Arcane. She reached out to me,
        and let me know what her conditions were, shown below:
        </p>
        <img  src={reqs}
              alt="Image of Artist's Requirements"
              style={{ width: "50vw" }}/>
        <p>
          Throughout the process of drawing, she continued to send me interminnent updates, starting with a sketch/wireframe, then 
          adding details that I wanted (such as a man bun), and then finally coloring and rendering the art piece, including making
          tweaks that I wanted throughout the process (such as darkening the back a little bit). Some images of the progress are shown below:
        </p>
        <img src={prog1} alt="Phase I of picture"
              style={{ width: "50vw" }}></img>
        <img src={prog2} alt="Phase II of picture"
              style={{ width: "50vw" }}></img>
        <img src={prog3}alt="Phase III of picture"
              style={{ width: "50vw" }}></img>
        <p>
          Overall, it was a very positive experience, with the artist setting clear boundaries on what they wanted from me, and 
          me setting clear expectations of what I wanted from her. The transaction was 30$ total, with the artist normally taking
          50% up front and 50% later, but allowing me to pay later since she knows my sister well.
        </p>

        <h2>Reflection</h2>
        <h4>
          What did your notice or observe while doing this challenge? What did
          you learn, in general, from this challenge? What did you learn about
          your issue from this challenge?
        </h4>
        <p>
          It was quite a streamlined process, more than I thought it would be. And quite honestly, I recieved a product that 
          I never would have been able to make with AI, even with 100 years of prompting. Being able to connect with the artist
          and ask for exactly what I wanted was a novel experience, and it made me realize just how much AI art stifles curiosity
          and imagination by outputting generic and boring "artwork".
        </p>
        <h4>What was successful or least successful? Why?</h4>
        <p>
          I think the most successful part was the commissioning of the art itself. It was very quick, and she needed only a little bit of
          description as well as a source image to get started immediately. I honestly found myself in awe of how effective she was at
          understanding my intentions and bringing it to life. I really can't think of something that wasn't successful about this process,
          it really was just a generally positive experience from my end.
        </p>
        <h4>What might you do differently?</h4>
        <p>
          If I could do it differently, I would probably try approaching an artist online that I don't know beforehand rather than a 
          friend of my sister. I think it would have made the experience more "authentic" to how a regular experience of commissioning art 
          online goes, and would have given me some really great insights.
        </p>
        <h4>What questions do you have after completing this challenge?</h4>
        <p>
          I am curious what proportion of people who make use of AI art have actually tried commissioning art, and what the reasons are for
          people who make use from AI art. The first thing that comes to mind is cost, but I think for something like a profile picture,
          a painting, or generally something you want to admire, using AI art just seems... insufficient. Art is admired because of the skill
          (and honestly, cost) of obtaining it. There is no intrinsic value to AI generated art, whether from a human effort or monetary perspective, 
          so it seems sort of backwards to use AI for people who are perfectly capable of commisioning art.
        </p>
        <h4>
          What do you feel you’ve learned about social change or changemaking
          from completing this challenge?
        </h4>
        <p>
          Social change is an uphill battle. I may have helped out a single artist by creating a single commission, but they can't compete
          against the sheer efficiency and speed of a machine. It sort of reminds me of John Henry and the mining machine, where somoene's talent
          honed and polished over years and decades is "replicated" through a machine, which is then used to explicitly replace the person it was based off of.
          People like to follow the path of least resistance, and in the modern art economy, that means going for AI, even if it means artists suffer.
          Most people simply don't have the ability to create or the money to commission, so they turn to AI instead.
        </p>
        <h4>How will this challenge help you moving forward?</h4>
        <p>
          Moving forward, I think I'll be more amenable to commissioning art. It was an enjoyable experience, and a great first experience too.
          I often have pictures of characters or settings or people in my head that I would like to have for personal enjoyment, but don't have the time 
          to put towards actually making the art myself (I'm quite good at vector art), so this is a cool alternative that I will continue to use
          throughout my life if I ever want something drawn.
        </p>
      </>
    ),
    date: "12/6/24",
  },
  {
    title: "PLCY Changemaker Challenge 5",
    body: (
      <>
        <h2>Challenge Chosen, Supporting Materials</h2>
        <p>
          I did Challenge E, the Advocacy Challenge. I first started by figuring
          out who my elected officials were through{" "}
          <a href="https://www.maryland.gov/Pages/default.aspx">Maryland.gov</a>
          , figuring out who represented me at all levels of government, and who
          I would have to email for any given issue. Once I had that figured
          out, I started looking for an angle to lobby one of these officials
          from. I knew I wanted to talk in support of restricting AI and
          deepfake technologies in the social space, but I needed more
          information about past movements and laws passed.
        </p>
        <p>
          While I was searching, I found{" "}
          <a href="https://mgaleg.maryland.gov/mgawebsite/Legislation/Details/hb0145?ys=2024RS#:~:text=Establishing%20that%20the%20statute%20of,that%20is%20indistinguishable%20from%20an">
            HB0145
          </a>
          , a law meant to establish that unconsentual deep fake imagery can be
          considered harrassment and is illegal in the court of law up to 5
          years after it has been distributed. Notably, this didn't do much for
          the creation of deepfakes but for the distribution, but it was a solid
          start after Maryland has failed to get anything more than an election
          and elected official related deepfake law passed over the past year.
        </p>
        <p>
          This law had passed the house unanimously, but died in committee for
          some reason, and I wanted to urge my senator to reintroduce it in the
          next session. Thus, I sent an email to my senator representative Nancy
          King, urging her to do so. below is the email, as well as a screenshot
          showing the email's metadata. I have cut out my personal information
          from the end of the email
        </p>
        <h2>Email:</h2>
        <p>Dear Senator King,</p>I hope this email finds you well, and I wish
        you a happy Thanksgiving. My name is Nebil Ozer, and I am a resident of
        Gaithersburg in District 39. I am writing to express my concern
        regarding the misuse of deepfake technology and the significant harm it
        causes, particularly in the context of non-consensual explicit content
        and revenge porn.
        <p>
          Earlier this year, House Bill 145 (HB0145), which aimed to address
          these issues, passed unanimously in the House but did not advance out
          of the Senate Judicial Proceedings Committee. I believe this bill
          represents an essential step in protecting Maryland residents from the
          malicious use of synthetic media, and I urge you to consider
          supporting its reintroduction in the next legislative session.
        </p>
        The rise of deepfake technology has led to devastating consequences for
        victims whose likenesses are manipulated without consent. This issue is
        not only a violation of privacy but also a threat to public trust in
        digital content. Legislation like HB0145 would have established clear
        penalties for these harmful actions while providing much-needed recourse
        for victims, who would otherwise need to fight extended legal battles.
        <p>
          As someone from a Muslim household, modesty and privacy are deeply
          important cultural values. The violation that deepfakes represent
          conflicts with our belief in maintaining our personal dignity and
          protecting our image from misuse. This, combined with the social
          issues surrounding non consensual usage of one's image makes the harms
          of deepfake misuse all the more concerning to me.
        </p>
        Thank you for your time and for your dedication to serving our
        community, and I wish you all the best.
        <p>Sincerely, Nebil Ahmet Ozer</p>
        <img
          src={email}
          alt="Image of Email to Senator"
          style={{ width: "50vw" }}
        />
        <h2>Reflection Questions:</h2>
        <h4>
          What did your notice or observe while doing this challenge? What did
          you learn, in general, from this challenge? What did you learn about
          your issue from this challenge?
        </h4>
        <p>
          While working on this challenge, I noticed how complex the legislative
          process is, even for issues that seem straightforward, such as
          protecting people from harmful uses of technology like deepfakes.
          Despite unanimous support in one legislative chamber, a bill could
          still fail to progress, often due to procedural or committee-related
          obstacles. I also realized just how many people represent me in the
          government. From state, local, district, federal levels there are
          multiple people that each represent me and my interests.
        </p>
        <h4>What was successful or least successful? Why?</h4>
        <p>
          The most successful part was identifying a relevant piece of
          legislation (HB0145) and tailoring my advocacy efforts around it. It
          was impactful to base my email on concrete legislative history and
          align my concerns with an existing bill. The least successful part was
          not being able to gauge immediate feedback or impact from my senator's
          office. Although this is partly ince my email was sent during
          thanksgiving, I doubt a response would be quick (or come at all)
          during regular hours due to how busy they must be. I really felt like
          I was just one person out of hundreds of thousands
        </p>
        <h4>What might you do differently?</h4>
        <p>
          Next time, I would consider reaching out to additional officials or
          advocacy groups to amplify my voice and strengthen my impact. I might
          also keep up with these sorts of laws more actively in order to
          influence them when they're actually being discussed instead of a few
          months after. Additionally, I would research more about the reasons
          why the bill stalled in the committee to better address those
          obstacles.
        </p>
        <h4>What questions do you have after completing this challenge?</h4>
        <p>
          The biggest question I still had was "What specific arguments or data
          would most effectively convince legislators to act on deepfake-related
          issues?"
        </p>
        <h4>
          What do you feel you’ve learned about social change or changemaking
          from completing this challenge?
        </h4>
        <p>
          I’ve learned that social change often requires persistence and
          strategic communication. Even if an issue seems urgent or
          well-supported, advocacy efforts must align with political timelines,
          legislative processes, and the priorities of decision-makers.
          Changemaking is not just about passion for an issue—it's about
          consistently keeping up with the social environment and pushing where
          you'll make the most change. I doubt my email will make much
          difference now, but a well-timed email to the leader of the committee
          that rejected the bill could have made all the difference if I had
          known about it
        </p>
        <h4>How will this challenge help you moving forward?</h4>
        <p>
          Cold emailing and knowing who my representatives are are both solid
          things to keep in my back pocket. If I ever have an issue I'm just as
          interested in, I can just reach out just like I did today!
        </p>
      </>
    ),
    date: "11/29/24",
  },
  {
    title: "PLCY Changemaker Challenge 4",
    body: (
      <>
        <h2>Challenge Chosen, Supporting Materials</h2>
        <p>
          I did the Instagram Carousel Challenge. (Challenge J). I started by
          collecting a wide variety of statistics and into level information
          about my topic (Deepfakes, AI Art, and their social consequences), and
          went from there, splitting the information into 8 parts, designing,
          and eventually creating each slide (along with a title slide, 2 source
          slides, and an additional information/cool links slide)
        </p>
        <p>
          My carousel was made on Figma, a design tool that I've used in the
          past for UX/UI Design. Although there definitely were easier options
          using software made to create instagram content, I like the freedom
          that Figma brings, freely being able to drag things around, mess with
          text and images, and add my own spin to things. However, creating the
          slides in this way was very very exhausting and took far longer than I
          expected, while also resulting in a set of slides that are... rough
          around the edges. Either way, I'm satisfied with my creation, and you
          can find the link right below!
        </p>
        <a
          target="_blank"
          href="https://www.figma.com/design/6JONKOJY9gGnbP8SS3HJ3s/Deepfakes%26AI-Instagram-Carousel?node-id=0-1&node-type=canvas&t=nDABp40NtJNCEyPa-0"
        >
          {" "}
          https://www.figma.com/design/6JONKOJY9gGnbP8SS3HJ3s/Deepfakes%26AI-Instagram-Carousel?node-id=0-1&node-type=canvas&t=nDABp40NtJNCEyPa-0{" "}
        </a>
        <h2>Reflection</h2>
        <h4>
          What did your notice or observe while doing this challenge? What did
          you learn, in general, from this challenge? What did you learn about
          your issue from this challenge?
        </h4>
        <p>
          As I worked on this challenge, I noticed the nuanced ways that legal,
          ethical, and social issues overlap with AI-generated content,
          especially in the realms of deepfakes and AI art. The widespread
          access to these technologies has opened many doors for potential
          misuse, ones that are increasingly severe and difficult to catch, but
          also surprisingly hidden from the public eye. The introduction of
          memes and jokes on the internet about these technologies has led the
          public conciousness to mostly ignore the severe issues it brings to
          the table. Specifically, I observed that there is still a lack of
          clear legal frameworks to manage these new technologies, even with the
          risks they pose to intellectual property and even someone's bodily
          autonomy and image.
        </p>
        <h4>What was successful or least successful? Why?</h4>
        <p>
          One of the most successful aspects was the actual making of the
          carousel. Condensing complex issues into bite-sized, easily digestible
          content was challenging but effective in making the material
          accessible to a broader audience and pushed me to better understand my
          topic so that I am able to summarize it properly. However, I found it
          challenging to provide adequate context for all points within the
          limits of Instagram’s format, which may have left certain points
          feeling simplified. Balancing depth with simplicity was difficult,
          highlighting the need for clear prioritization when communicating
          complex topics. I often had to step back and cut some parts out in
          order to make sure that the page wasn't too overwhelming for the
          audience. Even then, I feel as though I could do with shortening quite
          a few of the slides I ended up with
        </p>
        <h4>What might you do differently?</h4>
        <p>
          I would definitely use a different software than figma. Although the
          increased freedom was great, I ended up using a lot more effort for a
          slightly worse looking end product. If I had used a tool purpose-built
          for this stuff, I definitely could have accomplished a lot more in
          less time.
        </p>
        <h4>What questions do you have after completing this challenge?</h4>
        <p>
          This project left me with some questions about instagram posts and
          social media reach out. I realized that there really is a lot more
          effort that goes into this sort of communication than I gave credit
          for, and am wondering how effective it actually is. Do people digest
          insights faster or more effectively this way? Is it worth weeks of
          effort just for most people to scroll by immediately? What numbers do
          the professionally-made instagram infographic carousels pull? How many
          people do these normally find?
        </p>
        <h4>
          What do you feel you’ve learned about social change or changemaking
          from completing this challenge?
        </h4>
        <p>
          Changemaking is hard, its hard to collect and refine and design so
          much just to have a higher chance of catching someone's eye and
          hopefully educating them about an issue. I've often scrolled past or
          looked through these sorts of instagram carousels, and never truly
          appreciated the time and dedication that others put in to get their
          message out there in such an easily digestible, convenient, and
          nice-looking way.
        </p>
        <h4>How will this challenge help you moving forward?</h4>
        <p>
          Although I did struggle with Figma, I think that my graphic design
          skills have definitely gone up a notch with this project. Also, I now
          know of these resources to help me create this sort of social media
          outreach if it ever comes down to it. Although I don't see myself
          doing much of this in the future, I'll definitely slow down and
          appreciate someone else's work and time whenever a well-crafted
          instagram carousel about something comes across my timeline.
        </p>
      </>
    ),
    date: "11/8/24",
  },
  {
    title: "PLCY Changemaker Challenge 3",
    body: (
      <>
        <h2>Event Details about the event (date, location, title, etc.)</h2>
        <p>
          The event I attended was hosted by the University of Reading, and was
          titled "Deepfakes and AI in Film and Media: Seeing is Not Believing".
          The event took place on on October 30, 2024 from 3:30 - 5:00 PM EST,
          and was led by Dr.Dominic Lees. Since The University of Reading is
          located in the UK, I was unable to attend in person, but attended the
          talk remotely.
        </p>
        <h2>Registration Confirmation, Video of event</h2>
        <h3>Here is the confirmation of my attendance/registration</h3>
        <img
          src={ConfirmationImage}
          alt="Image of Confirmation Email"
          style={{ width: "50vw" }}
        />
        <h3>Link to the recording of the event online:</h3>
        <a href="https://www.youtube.com/live/SkPT3ueTNvQ">
          https://www.youtube.com/live/SkPT3ueTNvQ
        </a>
        <h2>Event Summary</h2>
        <p>
          This lecture led by Dr.Lees had a bit of a "ted-talk" esque format,
          and explored the increasing use of AI and generative technology in
          media, focusing on the implications for public trust, democracy, and
          the entertainment industry. It highlighted the challenges posed by
          deepfakes and AI-generated content, emphasizing the potential risks
          and cultural impact as these technologies continue to evolve. Dr.Lees
          also discussed how deepfakes are being used not only in online
          misinformation campaigns but also in mainstream film production,
          showcasing both the creative potential of these innovations. As an
          insider to the industry, Dr.Lees had a wealth of examples and
          experience to share with the audience to punctuate his points about
          how exactly the film industry was both adapting to and fighting back
          against the inclusion of generative AI in filmmaking. The lecture
          aimed to raise awareness about how AI and deepfake technologies are
          blurring the lines between reality and fabrication, and the importance
          of developing policies and safeguards to address these emerging
          threats. The event encouraged participants to consider the broader
          societal impact of AI on truth, trust, and the future of digital
          media.
        </p>
        <h2>Takeaways</h2>
        <p>
          One of the most interesting parts of this event that I immediately
          noticed was that it was targeted towards a non-technical audience,
          targeting creative liberal arts majors rather than, say, STEM or
          Law-adjacent majors. As someone who is intimate with these
          technologies from a technical perspective, it was refreshing to see it
          from another point of view: a complex, difficult-to-grasp emerging
          technology that raises more questions than it answers as it gets
          increasingly capable.
        </p>
        <p>
          The event also raised some points that I had not come across yet, ways
          of using AI as a creative tool to augment existing media rather than
          replace it. Dr.Lees brought up the rise of fan casting, allowing
          individuals and fans to "recast" movie scenes with their own choice of
          actors. He also brought up the cultural revolution being brought about
          in documentary films, where important or long pieces of literature can
          be said in the voice of the person who wrote it, even if they are long
          deceased.
        </p>
        <p>
          These emerging ways to use this new technology in media were, however,
          dullened by the sobering dangers of these technologies. In a
          politically unstable time right before the incredibly close US
          elections, deepfakes can be used to disseminate untrue information
          incredibly quickly and potentially unfairly tilt the scales of the
          election towards a particular side. Additionally, unconsentual and
          explicit deepfakes have exploded in availability, with legal
          protections being offerred to victims only recently in the UK.
        </p>
        <h2>Reflection Prompts</h2>
        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From this event, I gained insight into both the positive and negative
          aspects of AI and deepfake technology in film and media. I learned
          about their creative potential in enhancing storytelling, such as fan
          casting and voice recreation of the deceased in video form, while also
          understanding the significant threats these technologies pose to both
          individuals and to general political stability. The discussion about
          AI being used in misinformation campaigns and unconsensual deepfake
          content highlighted the urgent need for regulations and safeguards.
        </p>

        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          A major success that I noticed in the event lay in its ability to
          effectively communicate the merging of a complex technical topic and a
          deeply creative field to a varied audience. The topic of deepfakes was
          wonderfully and consisely summarized in a way that was easy to pick
          up, and I personally found my knowledge of the filmmaking industry
          grow as a result of the examples and points made by Dr.Lees. However,
          I felt that the least successful aspect was that while the talk
          highlighted the risks, it did not offer many concrete solutions or
          strategies for addressing these issues. The focus was primarily on
          raising awareness rather than providing actionable steps to reduce the
          problems surrounding generative AI.
        </p>

        <h3>3. What might you do differently?</h3>
        <p>
          If I had another shot at this activity, I would definitely choose to
          attend the UMD talk that I was initially intending to attend. The link
          for the event I wanted to attend is{" "}
          <a target="_blank" href="https://talks.cs.umd.edu/talks/4013">
            https://talks.cs.umd.edu/talks/4013
          </a>
          , and was aimed more towards AI and the privacy risks introduced by it
          for the average person instead of its impact on the filmmaking
          industry. While the event I ended up attending was very eye-opening
          and allowed for reflection on these topics from a new direction, the
          original talk I meant to attend was more attuned to the direction that
          I was interested in researching.
        </p>

        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          As I continue to work with AI and deep learning technologies, it's
          important to consider the ethical and cultural sides of these
          innovations. Understanding how these technologies are perceived by the
          general public and the potential harm they could cause both to the
          public and to a vast industry such as filmmaking helps me take a more
          responsible approach in my work. Taking a peek at the good and bad of
          new emerging technologies and techniques on other industries will give
          me a more solid idea as to the greater context of any achievments I
          make as a STEM major.
        </p>

        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>
          After attending this event, I have several questions: What are some of
          the most effective measures to prevent the spread of harmful deepfake
          content, especially during politically sensitive times? How can
          harmful deepfakes be mitigated, especially in an era where
          fact-checking and correcting of information holds so little weight?
          How can we strike a balance between encouraging creative uses of
          deepfake technology in film and media while ensuring they aren't
          misused? What role can technologists like myself play in creating
          safeguards or tools to mitigate these risks?
        </p>
      </>
    ),
    date: "10/31/24",
  },
  {
    title: "PLCY Changemaker Challenge 1",
    body: (
      <>
        <h2>List of Contacts:</h2>
        <ul>
          <li>Brian Bothwell - Email</li>
          <li>Subbarao-Kambhampati - Email</li>
          <li>Sarah Jodka - Email</li>
          <li>Gregory Kollmer - Email</li>
          <li>Selva Ozer - Text</li>
        </ul>
        <h2>Some Notes About the Interviews:</h2>
        <p>
          I tried my best to ask questions that were related to or similar to
          the interview questions in the document, but I struggled to fit a few
          of them into the natural flow of conversation, and especially was
          limited on my first interview, which only lasted 15 minutes total
          meaning I couldn't get to one or two of the interview questions in the
          Changemaker Challenge Document.
        </p>
        <h2>
          Brian Bothwell Interview: Addressing the Challenges of Deepfakes
        </h2>

        <h3>What Does Brian Bothwell Do?</h3>
        <p>
          Brian Bothwell is a Director at the Government Accountability Office
          (GAO), where he works on technology assessments and creates reports
          about modern technology. He also writes tech spotlights to help the
          public understand emerging technologies like deepfakes and generative
          AI.
        </p>

        <h3>Why Are Deepfakes So Difficult to Address?</h3>
        <p>
          Brian explained that several agencies, including DARPA, are working on
          solutions like digital watermarks to identify deepfakes. Laws are
          starting to catch up, but deepfakes create complex problems, from
          spreading misinformation to creating non-consensual content.
        </p>

        <h3>Are Deepfakes Always Harmful or Can They Be Good?</h3>
        <p>
          Deepfakes aren't always bad—they can be used for creative purposes,
          like art and entertainment. However, they can also be harmful, like
          spreading false information or scamming people. Brian talked about the
          rights of public figures and fair use, discussing whether people
          should be able to control how their image is used.
        </p>

        <h3>
          What Protections Exist for the Average Person Against Deepfakes?
        </h3>
        <p>
          Legal protections for people affected by deepfakes are still weak. If
          someone's likeness is used without permission, it often means taking
          costly legal action. Enforcing these laws is also difficult,
          especially when the deepfake creators are anonymous.
        </p>

        <h3>What Are the Challenges in Defining and Detecting Deepfakes?</h3>
        <p>
          As tools to detect deepfakes improve, the deepfakes themselves are
          also getting more convincing. This raises questions about free speech
          and malicious intent, making it hard to clearly define what a deepfake
          is.
        </p>

        <h3>Who Is Most Affected by Deepfakes?</h3>
        <p>
          Deepfakes harm people whose images are used without consent, and they
          are also used in scams that target individuals and companies.
          Deepfakes make scams more believable and manipulative.
        </p>

        <h3>What Does the Future Hold for Deepfakes?</h3>
        <p>
          Deepfakes are expected to become more sophisticated, which could
          change industries like filmmaking. They present opportunities for
          creativity but also risks, like replacing actors or writers.
        </p>

        <h3>What Are the Potential Solutions for Deepfakes?</h3>
        <p>
          Possible solutions include using blockchain to verify content, but
          that can be complicated and costly. Creating a database of original
          content might help, but it’s difficult to maintain. Often, by the time
          a deepfake is exposed as fake, the damage is already done.
        </p>

        <h3>Conclusion</h3>
        <p>
          In summary, Brian Bothwell highlighted that deepfakes have both
          positive and negative aspects. They can be used creatively in fields
          like entertainment, adding unique effects to films or creating
          entirely new forms of visual storytelling. However, they also pose
          significant risks, such as spreading misinformation, violating
          privacy, and manipulating public opinion. These risks are particularly
          concerning when deepfakes are used in political campaigns or for
          malicious intent, as they can easily deceive people and cause
          widespread harm. Addressing these challenges will require a
          combination of improved detection technology, strong legal
          protections, and public education. Collaboration between
          technologists, lawmakers, and educators is essential to ensure
          deepfakes are used responsibly, and public awareness will be key in
          reducing the risks. Ultimately, only by working together can we create
          a safer environment where the positive uses of deepfakes are
          encouraged while minimizing their harmful impacts. Moreover, it is
          important to invest in research and development to create more
          advanced detection tools that can keep up with the evolving nature of
          deepfakes. Public awareness campaigns should also focus on educating
          people about the existence of deepfakes, how to identify them, and how
          to verify the authenticity of digital content. The role of social
          media platforms is also crucial, as they need to implement stricter
          policies and technologies to identify and flag deepfake content
          promptly. By fostering a culture of digital literacy and vigilance, we
          can mitigate the potential harms of deepfakes and harness their
          positive applications for creativity and innovation.
        </p>

        <h2>Selva Ozer Interview: The Impact of Generative AI on Artists</h2>

        <h3>What Is the History of Generative AI in Art?</h3>
        <p>
          Selva explained that early AI attempts at creating art were simple and
          not very impressive. When DALL-E was released in 2022, generative AI
          became more popular. People used tools like DALL-E and Midjourney for
          jokes and even misinformation, but there is still no proper regulation
          for this technology.
        </p>

        <h3>What Problems Has Generative AI Created?</h3>
        <p>
          Generative AI has a big environmental impact and raises issues with
          intellectual property. Many AI models use artists' work without their
          permission, which leads to copyright problems. It also threatens jobs
          in creative fields, as companies often choose cheaper AI-made content
          over hiring human artists.
        </p>

        <h3>
          What Protections Are Available for Artists Against Generative AI?
        </h3>
        <p>
          Some tools can help protect artwork from AI, like adding noise to
          confuse the models, but these aren't foolproof. Artists have limited
          ways to stop AI from using their work, especially if it’s publicly
          available.
        </p>

        <h3>How Does the Legality of Deepfakes Compare to Generative AI?</h3>
        <p>
          Selva pointed out that deepfakes tend to have more immediate
          consequences compared to generative AI, especially when used for
          misinformation or harassment. That’s why deepfakes are a bigger focus
          in discussions about AI regulation—they have a direct impact on
          people’s lives.
        </p>

        <h3>Who Is Most Affected by Generative AI?</h3>
        <p>
          People in the entertainment industry are the most affected by
          generative AI because it devalues their work. Selva also mentioned
          that other jobs, like those in food service and warehouses, might be
          at risk due to automation.
        </p>

        <h3>What Is the Future of Generative AI?</h3>
        <p>
          Selva believes generative AI will continue to spread into more
          industries, creating more challenges for artists. Artists will need to
          find new ways to protect their work from being used without
          permission.
        </p>

        <h3>How Can We Limit AI's Influence on Art?</h3>
        <p>
          Selva argued that artists should have the right to challenge the
          unauthorized use of their work by AI. There need to be laws that
          protect artists’ rights and ensure they keep ownership of their
          creative talents.
        </p>

        <h3>Why Is AI-Generated Art on the Rise?</h3>
        <p>
          Selva said that one reason AI art is becoming more common is that many
          business leaders focus only on saving money and don’t appreciate the
          value of human-created art. This attitude makes art feel less human
          and reduces it to just a product.
        </p>

        <h3>Conclusion</h3>
        <p>
          Selva Ozer explained that generative AI brings significant challenges
          to artists. While it has the potential to enhance creativity, offering
          new tools and techniques for artistic expression, it also threatens
          the value of human-created art and the livelihoods of artists who rely
          on their unique skills and creativity. Protecting artists' rights will
          require new laws, public awareness, and collaboration between AI
          developers and the creative community. These protections must ensure
          that artists have control over how their work is used and that they
          receive proper recognition and compensation for their contributions.
          Additionally, educating the public about the value of human-created
          art compared to AI-generated content is crucial. It is also important
          for artists to engage with technology to find ways in which AI can be
          used as a supportive tool rather than a replacement. This balance will
          help ensure that artists continue to play a central role in the
          cultural landscape, and that the unique value of human expression is
          not lost in the rush to embrace new technology. Furthermore,
          governments and policymakers must work closely with the creative
          community to develop fair regulations that safeguard artists'
          intellectual property while encouraging innovation. The public also
          plays a critical role in valuing and supporting human creativity by
          making informed choices about the content they consume. By fostering a
          greater appreciation for the skills and efforts of human artists,
          society can help ensure that artistic integrity is upheld.
          Collaboration between artists, technologists, and policymakers is key
          to creating an environment where both AI and human creativity can
          coexist, each enhancing the other without undermining the value of
          genuine artistic talent. Only by recognizing the irreplaceable
          contributions of human artists can we maintain a cultural landscape
          that is rich, diverse, and deeply connected to the human experience.
        </p>

        <br />
        <br />

        <h2> Reflection </h2>

        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From the interviews with Brian Bothwell and Selva Ozer, I learned that
          deepfakes and generative AI are causing a lot of problems in different
          parts of society. Deepfakes are hard to detect and regulate, while
          generative AI has a big impact on artists, especially with copyright
          and job security. Both of these technologies need better detection
          tools, public education, and updated laws to handle their risks
          effectively.
        </p>

        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          The interviews were successful in helping me understand both the good
          and bad sides of deepfakes and generative AI. The least successful
          part was finding solid solutions to these problems. Both technologies
          are changing so quickly that it's hard to make rules or protections
          that work well and keep up.
        </p>

        <h3>3. What might you do differently?</h3>
        <p>
          If I did this challenge again, I would focus more on finding solutions
          from policymakers and tech experts instead of governmental researchers
          and activists. Getting ideas from people working on legal and
          technical protections could give me a better idea of how to reduce the
          negative effects of these technologies.
        </p>

        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          This challenge helped me better understand how complex new
          technologies like deepfakes and generative AI are. Moving forward,
          I'll be more aware of the ethical and social issues that come with
          these technologies, like privacy, creativity, and misinformation.
          Knowing these things will help me take part in discussions about
          technology rules and responsible use.
        </p>

        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>
          After finishing this challenge, I have questions about how we can make
          rules that keep up with the fast growth of AI technologies. I'm also
          curious about how artists and tech experts can work together to
          protect creative rights while using new tools. Lastly, I wonder how
          public education can help people understand and recognize deepfakes
          and generative AI content.
        </p>
      </>
    ),
    date: "October 21, 2024",
  },
  {
    title: "PLCY Changemaker Challenge 2",
    body: (
      <>
        <h2>Reflection:</h2>
        <br />
        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From the challenge, I gained a deeper understanding of the risks posed
          by deepfake to personal and creative content. The documents I read
          mentioned that deepfakes not only have the potential to deceive
          audiences and influence public opinion but also present legal and
          ethical challenges around identity theft and intellectual property
          ownership. The increasing use of AI in generating fake media, music,
          and art raises new issues about consent and copyright, and has
          potential for great harm, both socially and politically.
        </p>
        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          The successful part of this challenge was the wide variety of
          different sources that I was able to find. From governmental documents
          to op-eds to legal journals to youtube videos, I found a really nice
          wide variety of sources. Least successful was the lack of social
          groups already tackling this issue. That is, I wasn't able to find a
          huge organization that was pursuing justice or legal action about my
          issue
        </p>
        <h3>3. What might you do differently?</h3>
        <p>
          If I were to approach this challenge again, I would also focus on
          conducting analysis of different countries' legal approaches to
          deepfakes and AI content theft. Understanding how various
          jurisdictions are tackling these challenges could provide insights
          into best practices and potential frameworks that could be adopted in
          the United States.
        </p>
        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          This challenge has reinforced the importance of staying informed about
          the ethical and legal implications that AI brings along with its
          advancement. Moving forward, I will consider the broader consequences
          of AI advancements in any related projects or research I do. The
          knowledge gained will also be invaluable in discussions and advocacy
          for better regulations and protections for individuals and creators
          affected by AI technologies.
        </p>
        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>After completing this challenge, several questions remain:</p>
        <ul>
          <li>
            How can legislation keep pace with the rapid advancements in AI
            technology without stifling innovation?
          </li>
          <li>
            What role should tech companies play in preventing the misuse of AI
            for creating deepfakes and stealing content?
          </li>
          <li>
            How can we effectively educate the public to recognize and respond
            to deepfakes and AI-generated content?
          </li>
          <li>
            Are there technological solutions, such as watermarking or AI-based
            detection systems, that can help user distignuish real from
            AI-generated?
          </li>
        </ul>
        <br />
        <br />
        <h2>List of Citations:</h2>
        <ol>
          <li>
            Anti-Defamation League. (2023, June 6).{" "}
            <em>
              The dangers of manipulated media and video: Deepfakes and more
            </em>
            . Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.adl.org/resources/blog/dangers-manipulated-media-and-video-deepfakes-and-more"
            >
              https://www.adl.org/resources/blog/dangers-manipulated-media-and-video-deepfakes-and-more
            </a>
          </li>
          <li>
            U.S. Department of Homeland Security. (2023).{" "}
            <em>Increasing threat of deepfake identities</em>. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf"
            >
              https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf
            </a>
          </li>
          <li>
            Center for Media Engagement. (2022, September 13).{" "}
            <em>
              Election Misinformation Symposium: Fighting misinfo through
              fact-checking and deepfake detection
            </em>{" "}
            [Video]. YouTube. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.youtube.com/watch?v=QlNGD_QLcZE"
            >
              https://www.youtube.com/watch?v=QlNGD_QLcZE
            </a>
          </li>
          <li>
            Groh, M., Sankaranarayanan, A., Singh, N., Kim, D. Y., Lippman, A.,
            &amp; Picard, R. (2024, September 2). Human detection of political
            speech deepfakes across transcripts, audio, and video.{" "}
            <em>Nature Communications</em>, 15(1), Article 51998.{" "}
            <a
              target="_blank"
              href="https://doi.org/10.1038/s41467-024-51998-z"
            >
              https://doi.org/10.1038/s41467-024-51998-z
            </a>
          </li>
          <li>
            Bond, S. (2024, February 8). AI fakes raise election risks as
            lawmakers and tech companies scramble to catch up. <em>NPR</em>.
            Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence"
            >
              https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence
            </a>
          </li>
          <li>
            Quirk, C. (2024). The high stakes of deepfakes: The growing
            necessity of federal legislation to regulate this rapidly evolving
            technology. <em>Princeton Legal Journal</em>. Retrieved from{" "}
            <a
              target="_blank"
              href="https://legaljournal.princeton.edu/the-high-stakes-of-deepfakes-the-growing-necessity-of-federal-legislation-to-regulate-this-rapidly-evolving-technology/"
            >
              https://legaljournal.princeton.edu/the-high-stakes-of-deepfakes-the-growing-necessity-of-federal-legislation-to-regulate-this-rapidly-evolving-technology/
            </a>
          </li>
          <li>
            National Conference of State Legislatures. (2024, May 7). Deceptive
            audio or visual media (‘deepfakes’) 2024 legislation. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.ncsl.org/technology-and-communication/deceptive-audio-or-visual-media-deepfakes-2024-legislation"
            >
              https://www.ncsl.org/technology-and-communication/deceptive-audio-or-visual-media-deepfakes-2024-legislation
            </a>
          </li>
          <li>
            DMCA Agent Service. (2019, August 6).{" "}
            <em>Deepfakes - Can you use copyright law and the DMCA?</em>{" "}
            [Video]. YouTube. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.youtube.com/watch?v=_dVFkw9FJPI"
            >
              https://www.youtube.com/watch?v=_dVFkw9FJPI
            </a>
          </li>
          <li>
            Chayka, K. (2023, February 10). Is A.I. art stealing from artists?{" "}
            <em>The New Yorker</em>. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists"
            >
              https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists
            </a>
          </li>
          <li>
            Olson, Z. (2024, February 28). Op-Ed: AI art is art theft and should
            be a crime. <em>The Eagle Online</em>. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.theeagleonline.com/article/2024/01/op-ed-ai-art-is-art-theft-and-should-be-a-crime"
            >
              https://www.theeagleonline.com/article/2024/01/op-ed-ai-art-is-art-theft-and-should-be-a-crime
            </a>
          </li>
          <li>
            Cole, C., &amp; Aft, A. (2024, August 14). US Copyright Office calls
            for federal law on deepfakes. Retrieved from{" "}
            <a
              target="_blank"
              href="https://www.connectontech.com/us-copyright-office-calls-for-federal-law-on-deepfakes/"
            >
              https://www.connectontech.com/us-copyright-office-calls-for-federal-law-on-deepfakes/
            </a>
          </li>
          <li>
            Extra Credits. (2023, February 8).{" "}
            <em>AI Art: Copyright, Ownership and Infringement (oh my!)</em>{" "}
            [Video]. YouTube.{" "}
            <a
              target="_blank"
              href="https://www.youtube.com/watch?v=SvV8hZg9-XI"
            >
              https://www.youtube.com/watch?v=SvV8hZg9-XI
            </a>
          </li>
          <li>
            Bloomberg Law. (2023, June 26).{" "}
            <em>
              ChatGPT and Generative AI Are Hits! Can Copyright Law Stop Them?
            </em>{" "}
            [Video]. YouTube.{" "}
            <a
              target="_blank"
              href="https://www.youtube.com/watch?v=bRqwTP2eKJY"
            >
              https://www.youtube.com/watch?v=bRqwTP2eKJY
            </a>
          </li>
          <li>
            LegalEagle. (2023, January 26). <em>A.I. Versus The Law</em>{" "}
            [Video]. YouTube.{" "}
            <a
              target="_blank"
              href="https://www.youtube.com/watch?v=G08hY8dSrUY"
            >
              https://www.youtube.com/watch?v=G08hY8dSrUY
            </a>
          </li>
          <li>
            Klobuchar, A. (2024, September).{" "}
            <em>
              Klobuchar, colleagues urge Justice Department, Federal Trade
              Commission to investigate generative AI products for potential
              antitrust violations
            </em>{" "}
            [Press release].{" "}
            <a
              target="_blank"
              href="https://www.klobuchar.senate.gov/public/index.cfm/2024/9/klobuchar-colleagues-urge-justice-department-federal-trade-commission-to-investigate-generative-ai-products-for-potential-antitrust-violations"
            >
              https://www.klobuchar.senate.gov/public/index.cfm/2024/9/klobuchar-colleagues-urge-justice-department-federal-trade-commission-to-investigate-generative-ai-products-for-potential-antitrust-violations
            </a>
          </li>
        </ol>
      </>
    ),
    date: "September 27, 2024",
  },
];
