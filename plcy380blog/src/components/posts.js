import ConfirmationImage from "./img/image.png";

export const posts = [
  {
    title: "PLCY Changemaker Challenge 3",
    body: (
      <>
        <h2>Event Details about the event (date, location, title, etc.)</h2>
        <p>
          The event I attended was hosted by the University of Reading, and was
          titled "Deepfakes and AI in Film and Media: Seeing is Not Believing".
          The event took place on on October 30, 2024 from 3:30 - 5:00 PM EST,
          and was led by Dr.Dominic Lees. Since The University of Reading is
          located in the UK, I was unable to attend in person, but attended the
          talk remotely.
        </p>
        <h2>Registration Confirmation, Video of event</h2>
        <h3>Here is the confirmation of my attendance/registration</h3>
        <img src={ConfirmationImage} alt="Image of Confirmation Email"></img>
        <h3>Link to the recording of the event online:</h3>
        <a href="https://www.youtube.com/live/SkPT3ueTNvQ">
          https://www.youtube.com/live/SkPT3ueTNvQ
        </a>
        <h2>Event Summary</h2>
        <p>
          This lecture led by Dr.Lees had a bit of a "ted-talk" esque format,
          and explored the increasing use of AI and generative technology in
          media, focusing on the implications for public trust, democracy, and
          the entertainment industry. It highlighted the challenges posed by
          deepfakes and AI-generated content, emphasizing the potential risks
          and cultural impact as these technologies continue to evolve. Dr.Lees
          also discussed how deepfakes are being used not only in online
          misinformation campaigns but also in mainstream film production,
          showcasing both the creative potential of these innovations. As an
          insider to the industry, Dr.Lees had a wealth of examples and
          experience to share with the audience to punctuate his points about
          how exactly the film industry was both adapting to and fighting back
          against the inclusion of generative AI in filmmaking. The lecture
          aimed to raise awareness about how AI and deepfake technologies are
          blurring the lines between reality and fabrication, and the importance
          of developing policies and safeguards to address these emerging
          threats. The event encouraged participants to consider the broader
          societal impact of AI on truth, trust, and the future of digital
          media.
        </p>
        <h2>Takeaways</h2>
        <p>
          One of the most interesting parts of this event that I immediately
          noticed was that it was targeted towards a non-technical audience,
          targeting creative liberal arts majors rather than, say, STEM or
          Law-adjacent majors. As someone who is intimate with these
          technologies from a technical perspective, it was refreshing to see it
          from another point of view: a complex, difficult-to-grasp emerging
          technology that raises more questions than it answers as it gets
          increasingly capable.
        </p>
        <p>
          The event also raised some points that I had not come across yet, ways
          of using AI as a creative tool to augment existing media rather than
          replace it. Dr.Lees brought up the rise of fan casting, allowing
          individuals and fans to "recast" movie scenes with their own choice of
          actors. He also brought up the cultural revolution being brought about
          in documentary films, where important or long pieces of literature can
          be said in the voice of the person who wrote it, even if they are long
          deceased.
        </p>
        <p>
          These emerging ways to use this new technology in media were, however,
          dullened by the sobering dangers of these technologies. In a
          politically unstable time right before the incredibly close US
          elections, deepfakes can be used to disseminate untrue information
          incredibly quickly and potentially unfairly tilt the scales of the
          election towards a particular side. Additionally, unconsentual and
          explicit deepfakes have exploded in availability, with legal
          protections being offerred to victims only recently in the UK.
        </p>
        <h2>Reflection Prompts</h2>
        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From this event, I gained insight into both the positive and negative
          aspects of AI and deepfake technology in film and media. I learned
          about their creative potential in enhancing storytelling, such as fan
          casting and voice recreation of the deceased in video form, while also
          understanding the significant threats these technologies pose to both
          individuals and to general political stability. The discussion about
          AI being used in misinformation campaigns and unconsensual deepfake
          content highlighted the urgent need for regulations and safeguards.
        </p>

        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          A major success that I noticed in the event lay in its ability to
          effectively communicate the merging of a complex technical topic and a
          deeply creative field to a varied audience. The topic of deepfakes was
          wonderfully and consisely summarized in a way that was easy to pick
          up, and I personally found my knowledge of the filmmaking industry
          grow as a result of the examples and points made by Dr.Lees. However,
          I felt that the least successful aspect was that while the talk
          highlighted the risks, it did not offer many concrete solutions or
          strategies for addressing these issues. The focus was primarily on
          raising awareness rather than providing actionable steps to reduce the
          problems surrounding generative AI.
        </p>

        <h3>3. What might you do differently?</h3>
        <p>
          If I had another shot at this activity, I would definitely choose to
          attend the UMD talk that I was initially intending to attend. The link
          for the event I wanted to attend is{" "}
          <a href="https://talks.cs.umd.edu/talks/4013">
            https://talks.cs.umd.edu/talks/4013
          </a>
          , and was aimed more towards AI and the privacy risks introduced by it
          for the average person instead of its impact on the filmmaking
          industry. While the event I ended up attending was very eye-opening
          and allowed for reflection on these topics from a new direction, the
          original talk I meant to attend was more attuned to the direction that
          I was interested in researching.
        </p>

        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          As I continue to work with AI and deep learning technologies, it's
          important to consider the ethical and cultural sides of these
          innovations. Understanding how these technologies are perceived by the
          general public and the potential harm they could cause both to the
          public and to a vast industry such as filmmaking helps me take a more
          responsible approach in my work. Taking a peek at the good and bad of
          new emerging technologies and techniques on other industries will give
          me a more solid idea as to the greater context of any achievments I
          make as a STEM major.
        </p>

        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>
          After attending this event, I have several questions: What are some of
          the most effective measures to prevent the spread of harmful deepfake
          content, especially during politically sensitive times? How can
          harmful deepfakes be mitigated, especially in an era where
          fact-checking and correcting of information holds so little weight?
          How can we strike a balance between encouraging creative uses of
          deepfake technology in film and media while ensuring they aren't
          misused? What role can technologists like myself play in creating
          safeguards or tools to mitigate these risks?
        </p>
      </>
    ),
    date: "10/31/24",
  },
  {
    title: "PLCY Changemaker Challenge 1",
    body: (
      <>
        <h2>List of Contacts:</h2>
        <ul>
          <li>Brian Bothwell - Email</li>
          <li>Subbarao-Kambhampati - Email</li>
          <li>Sarah Jodka - Email</li>
          <li>Gregory Kollmer - Email</li>
          <li>Selva Ozer - Text</li>
        </ul>
        <h2>Some Notes About the Interviews:</h2>
        <p>
          I tried my best to ask questions that were related to or similar to
          the interview questions in the document, but I struggled to fit a few
          of them into the natural flow of conversation, and especially was
          limited on my first interview, which only lasted 15 minutes total
          meaning I couldn't get to one or two of the interview questions in the
          Changemaker Challenge Document.
        </p>
        <h2>
          Brian Bothwell Interview: Addressing the Challenges of Deepfakes
        </h2>

        <h3>What Does Brian Bothwell Do?</h3>
        <p>
          Brian Bothwell is a Director at the Government Accountability Office
          (GAO), where he works on technology assessments and creates reports
          about modern technology. He also writes tech spotlights to help the
          public understand emerging technologies like deepfakes and generative
          AI.
        </p>

        <h3>Why Are Deepfakes So Difficult to Address?</h3>
        <p>
          Brian explained that several agencies, including DARPA, are working on
          solutions like digital watermarks to identify deepfakes. Laws are
          starting to catch up, but deepfakes create complex problems, from
          spreading misinformation to creating non-consensual content.
        </p>

        <h3>Are Deepfakes Always Harmful or Can They Be Good?</h3>
        <p>
          Deepfakes aren't always bad—they can be used for creative purposes,
          like art and entertainment. However, they can also be harmful, like
          spreading false information or scamming people. Brian talked about the
          rights of public figures and fair use, discussing whether people
          should be able to control how their image is used.
        </p>

        <h3>
          What Protections Exist for the Average Person Against Deepfakes?
        </h3>
        <p>
          Legal protections for people affected by deepfakes are still weak. If
          someone's likeness is used without permission, it often means taking
          costly legal action. Enforcing these laws is also difficult,
          especially when the deepfake creators are anonymous.
        </p>

        <h3>What Are the Challenges in Defining and Detecting Deepfakes?</h3>
        <p>
          As tools to detect deepfakes improve, the deepfakes themselves are
          also getting more convincing. This raises questions about free speech
          and malicious intent, making it hard to clearly define what a deepfake
          is.
        </p>

        <h3>Who Is Most Affected by Deepfakes?</h3>
        <p>
          Deepfakes harm people whose images are used without consent, and they
          are also used in scams that target individuals and companies.
          Deepfakes make scams more believable and manipulative.
        </p>

        <h3>What Does the Future Hold for Deepfakes?</h3>
        <p>
          Deepfakes are expected to become more sophisticated, which could
          change industries like filmmaking. They present opportunities for
          creativity but also risks, like replacing actors or writers.
        </p>

        <h3>What Are the Potential Solutions for Deepfakes?</h3>
        <p>
          Possible solutions include using blockchain to verify content, but
          that can be complicated and costly. Creating a database of original
          content might help, but it’s difficult to maintain. Often, by the time
          a deepfake is exposed as fake, the damage is already done.
        </p>

        <h3>Conclusion</h3>
        <p>
          In summary, Brian Bothwell highlighted that deepfakes have both
          positive and negative aspects. They can be used creatively in fields
          like entertainment, adding unique effects to films or creating
          entirely new forms of visual storytelling. However, they also pose
          significant risks, such as spreading misinformation, violating
          privacy, and manipulating public opinion. These risks are particularly
          concerning when deepfakes are used in political campaigns or for
          malicious intent, as they can easily deceive people and cause
          widespread harm. Addressing these challenges will require a
          combination of improved detection technology, strong legal
          protections, and public education. Collaboration between
          technologists, lawmakers, and educators is essential to ensure
          deepfakes are used responsibly, and public awareness will be key in
          reducing the risks. Ultimately, only by working together can we create
          a safer environment where the positive uses of deepfakes are
          encouraged while minimizing their harmful impacts. Moreover, it is
          important to invest in research and development to create more
          advanced detection tools that can keep up with the evolving nature of
          deepfakes. Public awareness campaigns should also focus on educating
          people about the existence of deepfakes, how to identify them, and how
          to verify the authenticity of digital content. The role of social
          media platforms is also crucial, as they need to implement stricter
          policies and technologies to identify and flag deepfake content
          promptly. By fostering a culture of digital literacy and vigilance, we
          can mitigate the potential harms of deepfakes and harness their
          positive applications for creativity and innovation.
        </p>

        <h2>Selva Ozer Interview: The Impact of Generative AI on Artists</h2>

        <h3>What Is the History of Generative AI in Art?</h3>
        <p>
          Selva explained that early AI attempts at creating art were simple and
          not very impressive. When DALL-E was released in 2022, generative AI
          became more popular. People used tools like DALL-E and Midjourney for
          jokes and even misinformation, but there is still no proper regulation
          for this technology.
        </p>

        <h3>What Problems Has Generative AI Created?</h3>
        <p>
          Generative AI has a big environmental impact and raises issues with
          intellectual property. Many AI models use artists' work without their
          permission, which leads to copyright problems. It also threatens jobs
          in creative fields, as companies often choose cheaper AI-made content
          over hiring human artists.
        </p>

        <h3>
          What Protections Are Available for Artists Against Generative AI?
        </h3>
        <p>
          Some tools can help protect artwork from AI, like adding noise to
          confuse the models, but these aren't foolproof. Artists have limited
          ways to stop AI from using their work, especially if it’s publicly
          available.
        </p>

        <h3>How Does the Legality of Deepfakes Compare to Generative AI?</h3>
        <p>
          Selva pointed out that deepfakes tend to have more immediate
          consequences compared to generative AI, especially when used for
          misinformation or harassment. That’s why deepfakes are a bigger focus
          in discussions about AI regulation—they have a direct impact on
          people’s lives.
        </p>

        <h3>Who Is Most Affected by Generative AI?</h3>
        <p>
          People in the entertainment industry are the most affected by
          generative AI because it devalues their work. Selva also mentioned
          that other jobs, like those in food service and warehouses, might be
          at risk due to automation.
        </p>

        <h3>What Is the Future of Generative AI?</h3>
        <p>
          Selva believes generative AI will continue to spread into more
          industries, creating more challenges for artists. Artists will need to
          find new ways to protect their work from being used without
          permission.
        </p>

        <h3>How Can We Limit AI's Influence on Art?</h3>
        <p>
          Selva argued that artists should have the right to challenge the
          unauthorized use of their work by AI. There need to be laws that
          protect artists’ rights and ensure they keep ownership of their
          creative talents.
        </p>

        <h3>Why Is AI-Generated Art on the Rise?</h3>
        <p>
          Selva said that one reason AI art is becoming more common is that many
          business leaders focus only on saving money and don’t appreciate the
          value of human-created art. This attitude makes art feel less human
          and reduces it to just a product.
        </p>

        <h3>Conclusion</h3>
        <p>
          Selva Ozer explained that generative AI brings significant challenges
          to artists. While it has the potential to enhance creativity, offering
          new tools and techniques for artistic expression, it also threatens
          the value of human-created art and the livelihoods of artists who rely
          on their unique skills and creativity. Protecting artists' rights will
          require new laws, public awareness, and collaboration between AI
          developers and the creative community. These protections must ensure
          that artists have control over how their work is used and that they
          receive proper recognition and compensation for their contributions.
          Additionally, educating the public about the value of human-created
          art compared to AI-generated content is crucial. It is also important
          for artists to engage with technology to find ways in which AI can be
          used as a supportive tool rather than a replacement. This balance will
          help ensure that artists continue to play a central role in the
          cultural landscape, and that the unique value of human expression is
          not lost in the rush to embrace new technology. Furthermore,
          governments and policymakers must work closely with the creative
          community to develop fair regulations that safeguard artists'
          intellectual property while encouraging innovation. The public also
          plays a critical role in valuing and supporting human creativity by
          making informed choices about the content they consume. By fostering a
          greater appreciation for the skills and efforts of human artists,
          society can help ensure that artistic integrity is upheld.
          Collaboration between artists, technologists, and policymakers is key
          to creating an environment where both AI and human creativity can
          coexist, each enhancing the other without undermining the value of
          genuine artistic talent. Only by recognizing the irreplaceable
          contributions of human artists can we maintain a cultural landscape
          that is rich, diverse, and deeply connected to the human experience.
        </p>

        <br />
        <br />

        <h2> Reflection </h2>

        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From the interviews with Brian Bothwell and Selva Ozer, I learned that
          deepfakes and generative AI are causing a lot of problems in different
          parts of society. Deepfakes are hard to detect and regulate, while
          generative AI has a big impact on artists, especially with copyright
          and job security. Both of these technologies need better detection
          tools, public education, and updated laws to handle their risks
          effectively.
        </p>

        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          The interviews were successful in helping me understand both the good
          and bad sides of deepfakes and generative AI. The least successful
          part was finding solid solutions to these problems. Both technologies
          are changing so quickly that it's hard to make rules or protections
          that work well and keep up.
        </p>

        <h3>3. What might you do differently?</h3>
        <p>
          If I did this challenge again, I would focus more on finding solutions
          from policymakers and tech experts instead of governmental researchers
          and activists. Getting ideas from people working on legal and
          technical protections could give me a better idea of how to reduce the
          negative effects of these technologies.
        </p>

        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          This challenge helped me better understand how complex new
          technologies like deepfakes and generative AI are. Moving forward,
          I'll be more aware of the ethical and social issues that come with
          these technologies, like privacy, creativity, and misinformation.
          Knowing these things will help me take part in discussions about
          technology rules and responsible use.
        </p>

        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>
          After finishing this challenge, I have questions about how we can make
          rules that keep up with the fast growth of AI technologies. I'm also
          curious about how artists and tech experts can work together to
          protect creative rights while using new tools. Lastly, I wonder how
          public education can help people understand and recognize deepfakes
          and generative AI content.
        </p>
      </>
    ),
    date: "October 21, 2024",
  },
  {
    title: "PLCY Changemaker Challenge 2",
    body: (
      <>
        <h2>Reflection:</h2>
        <br />
        <h3>1. What did you learn about your issue from this challenge?</h3>
        <p>
          From the challenge, I gained a deeper understanding of the risks posed
          by deepfake to personal and creative content. The documents I read
          mentioned that deepfakes not only have the potential to deceive
          audiences and influence public opinion but also present legal and
          ethical challenges around identity theft and intellectual property
          ownership. The increasing use of AI in generating fake media, music,
          and art raises new issues about consent and copyright, and has
          potential for great harm, both socially and politically.
        </p>
        <h3>2. What was successful or least successful? Why?</h3>
        <p>
          The successful part of this challenge was the wide variety of
          different sources that I was able to find. From governmental documents
          to op-eds to legal journals to youtube videos, I found a really nice
          wide variety of sources. Least successful was the lack of social
          groups already tackling this issue. That is, I wasn't able to find a
          huge organization that was pursuing justice or legal action about my
          issue
        </p>
        <h3>3. What might you do differently?</h3>
        <p>
          If I were to approach this challenge again, I would also focus on
          conducting analysis of different countries' legal approaches to
          deepfakes and AI content theft. Understanding how various
          jurisdictions are tackling these challenges could provide insights
          into best practices and potential frameworks that could be adopted in
          the United States.
        </p>
        <h3>4. How will this challenge help you moving forward?</h3>
        <p>
          This challenge has reinforced the importance of staying informed about
          the ethical and legal implications that AI brings along with its
          advancement. Moving forward, I will consider the broader consequences
          of AI advancements in any related projects or research I do. The
          knowledge gained will also be invaluable in discussions and advocacy
          for better regulations and protections for individuals and creators
          affected by AI technologies.
        </p>
        <h3>5. What questions do you have after completing this challenge?</h3>
        <p>After completing this challenge, several questions remain:</p>
        <ul>
          <li>
            How can legislation keep pace with the rapid advancements in AI
            technology without stifling innovation?
          </li>
          <li>
            What role should tech companies play in preventing the misuse of AI
            for creating deepfakes and stealing content?
          </li>
          <li>
            How can we effectively educate the public to recognize and respond
            to deepfakes and AI-generated content?
          </li>
          <li>
            Are there technological solutions, such as watermarking or AI-based
            detection systems, that can help user distignuish real from
            AI-generated?
          </li>
        </ul>
        <br />
        <br />
        <h2>List of Citations:</h2>
        <ol>
          <li>
            Anti-Defamation League. (2023, June 6).{" "}
            <em>
              The dangers of manipulated media and video: Deepfakes and more
            </em>
            . Retrieved from{" "}
            <a href="https://www.adl.org/resources/blog/dangers-manipulated-media-and-video-deepfakes-and-more">
              https://www.adl.org/resources/blog/dangers-manipulated-media-and-video-deepfakes-and-more
            </a>
          </li>
          <li>
            U.S. Department of Homeland Security. (2023).{" "}
            <em>Increasing threat of deepfake identities</em>. Retrieved from{" "}
            <a href="https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf">
              https://www.dhs.gov/sites/default/files/publications/increasing_threats_of_deepfake_identities_0.pdf
            </a>
          </li>
          <li>
            Center for Media Engagement. (2022, September 13).{" "}
            <em>
              Election Misinformation Symposium: Fighting misinfo through
              fact-checking and deepfake detection
            </em>{" "}
            [Video]. YouTube. Retrieved from{" "}
            <a href="https://www.youtube.com/watch?v=QlNGD_QLcZE">
              https://www.youtube.com/watch?v=QlNGD_QLcZE
            </a>
          </li>
          <li>
            Groh, M., Sankaranarayanan, A., Singh, N., Kim, D. Y., Lippman, A.,
            &amp; Picard, R. (2024, September 2). Human detection of political
            speech deepfakes across transcripts, audio, and video.{" "}
            <em>Nature Communications</em>, 15(1), Article 51998.{" "}
            <a href="https://doi.org/10.1038/s41467-024-51998-z">
              https://doi.org/10.1038/s41467-024-51998-z
            </a>
          </li>
          <li>
            Bond, S. (2024, February 8). AI fakes raise election risks as
            lawmakers and tech companies scramble to catch up. <em>NPR</em>.
            Retrieved from{" "}
            <a href="https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence">
              https://www.npr.org/2024/02/08/1229641751/ai-deepfakes-election-risks-lawmakers-tech-companies-artificial-intelligence
            </a>
          </li>
          <li>
            Quirk, C. (2024). The high stakes of deepfakes: The growing
            necessity of federal legislation to regulate this rapidly evolving
            technology. <em>Princeton Legal Journal</em>. Retrieved from{" "}
            <a href="https://legaljournal.princeton.edu/the-high-stakes-of-deepfakes-the-growing-necessity-of-federal-legislation-to-regulate-this-rapidly-evolving-technology/">
              https://legaljournal.princeton.edu/the-high-stakes-of-deepfakes-the-growing-necessity-of-federal-legislation-to-regulate-this-rapidly-evolving-technology/
            </a>
          </li>
          <li>
            National Conference of State Legislatures. (2024, May 7). Deceptive
            audio or visual media (‘deepfakes’) 2024 legislation. Retrieved from{" "}
            <a href="https://www.ncsl.org/technology-and-communication/deceptive-audio-or-visual-media-deepfakes-2024-legislation">
              https://www.ncsl.org/technology-and-communication/deceptive-audio-or-visual-media-deepfakes-2024-legislation
            </a>
          </li>
          <li>
            DMCA Agent Service. (2019, August 6).{" "}
            <em>Deepfakes - Can you use copyright law and the DMCA?</em>{" "}
            [Video]. YouTube. Retrieved from{" "}
            <a href="https://www.youtube.com/watch?v=_dVFkw9FJPI">
              https://www.youtube.com/watch?v=_dVFkw9FJPI
            </a>
          </li>
          <li>
            Chayka, K. (2023, February 10). Is A.I. art stealing from artists?{" "}
            <em>The New Yorker</em>. Retrieved from{" "}
            <a href="https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists">
              https://www.newyorker.com/culture/infinite-scroll/is-ai-art-stealing-from-artists
            </a>
          </li>
          <li>
            Olson, Z. (2024, February 28). Op-Ed: AI art is art theft and should
            be a crime. <em>The Eagle Online</em>. Retrieved from{" "}
            <a href="https://www.theeagleonline.com/article/2024/01/op-ed-ai-art-is-art-theft-and-should-be-a-crime">
              https://www.theeagleonline.com/article/2024/01/op-ed-ai-art-is-art-theft-and-should-be-a-crime
            </a>
          </li>
          <li>
            Cole, C., &amp; Aft, A. (2024, August 14). US Copyright Office calls
            for federal law on deepfakes. Retrieved from{" "}
            <a href="https://www.connectontech.com/us-copyright-office-calls-for-federal-law-on-deepfakes/">
              https://www.connectontech.com/us-copyright-office-calls-for-federal-law-on-deepfakes/
            </a>
          </li>
          <li>
            Extra Credits. (2023, February 8).{" "}
            <em>AI Art: Copyright, Ownership and Infringement (oh my!)</em>{" "}
            [Video]. YouTube.{" "}
            <a href="https://www.youtube.com/watch?v=SvV8hZg9-XI">
              https://www.youtube.com/watch?v=SvV8hZg9-XI
            </a>
          </li>
          <li>
            Bloomberg Law. (2023, June 26).{" "}
            <em>
              ChatGPT and Generative AI Are Hits! Can Copyright Law Stop Them?
            </em>{" "}
            [Video]. YouTube.{" "}
            <a href="https://www.youtube.com/watch?v=bRqwTP2eKJY">
              https://www.youtube.com/watch?v=bRqwTP2eKJY
            </a>
          </li>
          <li>
            LegalEagle. (2023, January 26). <em>A.I. Versus The Law</em>{" "}
            [Video]. YouTube.{" "}
            <a href="https://www.youtube.com/watch?v=G08hY8dSrUY">
              https://www.youtube.com/watch?v=G08hY8dSrUY
            </a>
          </li>
          <li>
            Klobuchar, A. (2024, September).{" "}
            <em>
              Klobuchar, colleagues urge Justice Department, Federal Trade
              Commission to investigate generative AI products for potential
              antitrust violations
            </em>{" "}
            [Press release].{" "}
            <a href="https://www.klobuchar.senate.gov/public/index.cfm/2024/9/klobuchar-colleagues-urge-justice-department-federal-trade-commission-to-investigate-generative-ai-products-for-potential-antitrust-violations">
              https://www.klobuchar.senate.gov/public/index.cfm/2024/9/klobuchar-colleagues-urge-justice-department-federal-trade-commission-to-investigate-generative-ai-products-for-potential-antitrust-violations
            </a>
          </li>
        </ol>
      </>
    ),
    date: "September 27, 2024",
  },
];
